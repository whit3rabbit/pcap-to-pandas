{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scapy\n",
    "#!pip install pandas\n",
    "#!pip install matplotlib\n",
    "#!pip install networkx\n",
    "#!pip install polars\n",
    "#!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scapy.all import * # Packet manipulation\n",
    "import polars as pl # Pandas - Create and Manipulate DataFrames\n",
    "from datetime import datetime # Datetime - Convert Epoch to Datetime\n",
    "import ipaddress # IPAddress - Check for multicast and broadcast addresses\n",
    "import time # Measure time it takes to run\n",
    "import csv # CSV - Write to CSV\n",
    "import pyarrow.parquet as pq # PyArrow - Write to Parquet\n",
    "import pyarrow.csv as pv # PyArrow - Read CSV\n",
    "import re # Regex for name generation of files\n",
    "\n",
    "#import networkx as nx # NetworkX - Create and Manipulate Graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcap_name = \"The Ultimate PCAP v20221220.pcapng\"\n",
    "csv_file_name = re.sub(r'[^\\w\\s]', '', pcap_name).replace(\" \", \"_\") + \".csv\"\n",
    "parquet_file_name = re.sub(r'[^\\w\\s]', '', pcap_name).replace(\" \", \"_\") + \".parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_to_numbers = {'hopopt': 0, 'icmp': 1, 'igmp': 2, 'ggp': 3, 'ipv4': 4, 'st': 5, 'tcp': 6, 'cbt': 7, \n",
    "    'egp': 8, 'igp': 9, 'bbn-rcc-mon': 10, 'nvp-ii': 11, 'pup': 12, 'emcon': 14, 'xnet': 15, 'chaos': 16, 'udp': 17, 'mux': 18,\n",
    "    'dcn-meas': 19, 'hmp': 20, 'prm': 21, 'xns-idp': 22, 'trunk-1': 23, 'trunk-2': 24, 'leaf-1': 25, 'leaf-2': 26, 'rdp': 27, \n",
    "    'irtp': 28, 'iso-tp4': 29, 'netblt': 30, 'mfe-nsp': 31, 'merit-inp': 32, 'dccp': 33, '3pc': 34, 'idpr': 35, 'xtp': 36, \n",
    "    'ddp': 37, 'idpr-cmtp': 38, 'tp++': 39, 'il': 40, 'ipv6': 41, 'sdrp': 42, 'ipv6-route': 43, 'ipv6-frag': 44, 'idrp': 45,\n",
    "    'rsvp': 46, 'gre': 47, 'dsr': 48, 'bna': 49, 'esp': 50, 'ah': 51, 'i-nlsp': 52, 'narp': 54, 'mobile': 55, 'tlsp': 56, \n",
    "    'skip': 57, 'ipv6-icmp': 58, 'ipv6-nonxt': 59, 'ipv6-opts': 60, 'cftp': 62, 'sat-expak': 64, 'kryptolan': 65, 'rvd': 66,\n",
    "    'ippc': 67, 'sat-mon': 69, 'visa': 70, 'ipcv': 71, 'cpnx': 72, 'cphb': 73, 'wsn': 74, 'pvp': 75, 'br-sat-mon': 76, \n",
    "    'sun-nd': 77, 'wb-mon': 78, 'wb-expak': 79, 'iso-ip': 80, 'vmtp': 81, 'secure-vmtp': 82, 'vines': 83, 'ttp': 84,\n",
    "    'iptm': 84, 'nsfnet-igp': 85, 'dgp': 86, 'tcf': 87, 'eigrp': 88, 'ospfigp': 89, 'sprite-rpc': 90,\n",
    "    'larp': 91, 'mtp': 92, 'ax.25': 93, 'ipip': 94, 'scc-sp': 96, 'etherip': 97, 'encap': 98, 'gmtp': 100, \n",
    "    'ifmp': 101, 'pnni': 102, 'pim': 103, 'aris': 104, 'scps': 105, 'qnx': 106, 'a/n': 107, 'ipcomp': 108, \n",
    "    'snp': 109, 'compaq-peer': 110, 'ipx-in-ip': 111, 'vrrp': 112, 'pgm': 113, 'l2tp': 115, 'ddx': 116, 'iatp': 117, \n",
    "    'stp': 118, 'srp': 119, 'uti': 120, 'smp': 121, 'ptp': 123, 'fire': 125, 'crtp': 126, 'crudp': 127, 'sscopmce': 128, \n",
    "    'iplt': 129, 'sps': 130, 'pipe': 131, 'sctp': 132, 'fc': 133, 'rsvp-e2e-ignore': 134, 'udplite': 136, 'mpls-in-ip': 137,\n",
    "      'manet': 138, 'hip': 139, 'shim6': 140, 'wesp': 141, 'rohc': 142, 'ethernet': 143, 'aggfrag': 144, 'rsvp-e2e': 145}\n",
    "\n",
    "# https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml\n",
    "\n",
    "def get_protocol_name(protocol_number):\n",
    "    for protocol_name, number in protocol_to_numbers.items():\n",
    "        if number == protocol_number:\n",
    "            return protocol_name\n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAPToDataFrame:\n",
    "    def __init__(self):\n",
    "        self.capture_file = pcap_name\n",
    "        self.parquet_file = parquet_file_name\n",
    "        \n",
    "        # Create new CSV file and remove old one\n",
    "        self.csv_file_name = csv_file_name\n",
    "        self.headers = [\"time\",\"src_ip\",\"src_mac\",\"dst_ip\",\"dst_mac\",\"protocol\",\"payload_size\",\"multicast\",\"private_to_private\",\"dst_broadcast\",\"src_port\",\"dst_port\"]\n",
    "        if os.path.exists(self.csv_file_name):\n",
    "            os.remove(self.csv_file_name)\n",
    "        with open(self.csv_file_name, 'w') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=self.headers)\n",
    "            writer.writeheader()\n",
    "        f.close()\n",
    "\n",
    "    # Check if ip is multicast and private>private and broadcast\n",
    "    def check_multicast_and_private(self, packet, data):\n",
    "        src_ip = ipaddress.ip_address(packet[IP].src)\n",
    "        dst_ip = ipaddress.ip_address(packet[IP].dst)\n",
    "        if src_ip.is_multicast or dst_ip.is_multicast:\n",
    "            data[\"multicast\"] = True\n",
    "        else:\n",
    "            data[\"multicast\"] = False\n",
    "\n",
    "        if src_ip.is_private and dst_ip.is_private:\n",
    "            data[\"private_to_private\"] = True\n",
    "        else:\n",
    "            data[\"private_to_private\"] = False\n",
    "\n",
    "        if not dst_ip.is_global and dst_ip.is_link_local:\n",
    "            data[\"dst_broadcast\"] = True\n",
    "        else:\n",
    "            data[\"dst_broadcast\"] = False\n",
    "\n",
    "    # Extract the port numbers\n",
    "    def extract_port_numbers(self, packet, data):\n",
    "        if packet.haslayer(TCP):\n",
    "            data[\"src_port\"] = int(packet[TCP].sport)\n",
    "            data[\"dst_port\"] = int(packet[TCP].dport)\n",
    "        elif packet.haslayer(UDP):\n",
    "            data[\"src_port\"] = int(packet[UDP].sport)\n",
    "            data[\"dst_port\"] = int(packet[UDP].dport)\n",
    "\n",
    "    # Extract the conversations from the packet\n",
    "    def conversations_extract(self, packet):\n",
    "\n",
    "        # Check if the packet has the IP and Ethernet layers\n",
    "        if not packet.haslayer(IP) or not packet.haslayer(Ether):\n",
    "            return\n",
    "        \n",
    "        # Convert the timestamp to a readable UTC time\n",
    "        time = datetime.utcfromtimestamp(int(packet.time)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        protocol = get_protocol_name(int(packet[IP].proto))\n",
    "\n",
    "        # Extract the desired data from the packet\n",
    "        data = {\n",
    "            \"time\": time,\n",
    "            \"src_ip\": packet[IP].src,\n",
    "            \"src_mac\": packet[Ether].src,\n",
    "            \"dst_ip\": packet[IP].dst,\n",
    "            \"dst_mac\": packet[Ether].dst,\n",
    "            \"protocol\": protocol,\n",
    "            \"payload_size\": len(packet[IP].payload)\n",
    "        }\n",
    "\n",
    "        # Extract\n",
    "        self.check_multicast_and_private(packet, data)\n",
    "        self.extract_port_numbers(packet, data)\n",
    "\n",
    "        # Write the row to a csv file\n",
    "        self.writer.writerow(data)\n",
    "\n",
    "    def read_pcap_to_dataframe(self):\n",
    "        def conversations_extract_wrapper(packet):\n",
    "            self.conversations_extract(packet)\n",
    "\n",
    "        # Start time to read pcap time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Read the PCAP file and extract the data\n",
    "        with open(self.csv_file_name, 'a') as f:\n",
    "            self.writer = csv.DictWriter(f, fieldnames=self.headers)        \n",
    "            packets = sniff(offline=self.capture_file, prn=conversations_extract_wrapper, store=0)\n",
    "        f.close()\n",
    "\n",
    "        # Remove any previous parquet file\n",
    "        if os.path.exists(self.parquet_file):\n",
    "            os.remove(self.parquet_file)\n",
    "\n",
    "        # Convert the CSV file to a Parquet file\n",
    "        table = pv.read_csv(self.csv_file_name)\n",
    "        pq.write_table(table, self.parquet_file, compression='snappy')\n",
    "\n",
    "        # Remove the CSV file\n",
    "        if os.path.exists(self.csv_file_name):\n",
    "            os.remove(self.csv_file_name)\n",
    "        '''\n",
    "        File size differences using test 12mb pcap file:\n",
    "        12M  | pcapng\n",
    "        2.6M | csv\n",
    "        100K | parquet\n",
    "        '''\n",
    "        # Record time taken to process the PCAP file\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f'Elapsed time: {elapsed_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the PCAPToDataFrame class\n",
    "pcap_to_df = PCAPToDataFrame()\n",
    "\n",
    "# Read the PCAP file and create a csv\n",
    "pcap_to_df.read_pcap_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(parquet_file_name)\n",
    "df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ddc97ae128281c05480c1f8005c6b5489769cc6d6f9dc1223215b95e23507aa4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
